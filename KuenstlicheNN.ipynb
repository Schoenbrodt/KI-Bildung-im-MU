{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d19992c-6e54-43be-93fa-7ccd1e149c50",
   "metadata": {},
   "source": [
    "# Das Lernen eines einfachen neuronalen Netzes ist Optimierung von Parametern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e416816-1440-4829-916a-fe6eb7b9a023",
   "metadata": {},
   "source": [
    "Suche nach dem Minimum einer Funktion in einer Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c92c1e3-0434-4d6e-b0c9-3a13bd29db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Min des cos, Startwert 0.1', 3.141601562500001]\n",
      "['Min des cos, Startwert -0.1', -3.141601562500001]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def min1(f,x0):\n",
    "    delta=0.1 # anfängliche Schrittweite\n",
    "    while delta>0.0001:\n",
    "        while f(x0)>f(x0+delta) or f(x0)>f(x0-delta): # Solange Verbesserung möglich\n",
    "            if f(x0)>f(x0+delta): x0=x0+delta # gehe nach rechts\n",
    "            else: x0=x0-delta # oder links\n",
    "        delta=delta/2\n",
    "    return x0\n",
    "        \n",
    "print(['Min des cos, Startwert 0.1',min1(math.cos,0.1)])        \n",
    "print(['Min des cos, Startwert -0.1',min1(math.cos,-0.1)])  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f8bed09-a2f0-4f33-8682-50b762bcb043",
   "metadata": {},
   "source": [
    "Minimierung einer reellen Funktion auf R^n: Die Stelle ist also ein Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35af49e0-eb5e-4cf9-b0b5-112e5d6da62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Min in R^2', [2.0000000000000018, 3.0000000000000027]]\n"
     ]
    }
   ],
   "source": [
    "def minN(f,x0):\n",
    "    i=0\n",
    "    def fi(x): # Funktion R->R, bei der nur die i-te Komponente variabel\n",
    "        return f(x0[:i]+[x]+x0[i+1:])\n",
    "    for runde in range(100): # Anzahl der Durchgänge\n",
    "        for i in range(len(x0)): # Minimiere nacheinader bzgl der i-ten Variable\n",
    "            x0[i]=min1(fi,x0[i])\n",
    "    return x0\n",
    "\n",
    "def g(x): return (x[0]-2)**2+(x[1]-3)**2\n",
    "print(['Min in R^2',minN(g,[5,5])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68b637",
   "metadata": {},
   "source": [
    "Der Programmcode oben zeigt, dass die Suche nach einem Minimum einer Funktion R^n->R algorithmisch durchgeführt werden kann. Allerdings gibt es viel schnellere Implementationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42229fb3-b1e6-4d9c-811d-62f69bcf77d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99999986, 3.00000019])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "x0 = np.array([5,5])\n",
    "res = minimize(g, x0)\n",
    "res.x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dd53bed-6956-461f-a64d-4c765b68f850",
   "metadata": {},
   "source": [
    "Lineare Regression ist die Minimierung der Summe der quadratischen Abweichungen zwischen Daten und einem von einem Modell-Term vorhergesagten Wert. Die Parameter m,b der linearen Funktion y=m*x+b werden in einem Vektor x0=[m,b] gespeichert  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9099a8d3-e9e2-4efd-b5a3-6c24e4bc9189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59999997, 1.50000007])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[[1,3],[2,5],[3,6],[4,8]]\n",
    "def FehlerQuadrat(x0):\n",
    "    m=x0[0]; b=x0[1] # Parameter der Ausgleichsgerade\n",
    "    return sum([(d[1]-(m*d[0]+b))**2 for d in data]) # Summe der Abweichungsquadrate\n",
    "opt=minimize(FehlerQuadrat, np.array([0,0]))\n",
    "opt.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8832a-3172-4a42-82b8-5d22802fc660",
   "metadata": {},
   "source": [
    "Ein Neuron gewichtet einen Eingabevektor aus R^n mit einem Gewichtsvektor aus R^n und addiert eine Konstante. Danach wird die Sigmoid-Funktion angewendet. Die Funktion neuron illustriert das, wird später aber nicht mehr benötigt.\n",
    "Hat man mehr als ein Neuron kann man die Gewichtsvektoren in einer Matrix zusammenfassen und die additiven konstanten bilden einen Vektor. Auch die Sigmoid-Funktion muss dann auf einen Vektor angewendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70466776-6e1b-488c-ad06-4b442ce4dc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999983298578152"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "def sigmoid(x): return expit(x) # same as 1 / (1 + math.exp(-x)) but more stable for big numbers\n",
    "def sigmoidVect(x): return np.array([sigmoid(xi) for xi in x])\n",
    "def neuron(w, b,x):\n",
    "    z = w[-1]+sum([w[i] * x[i] for i in range(len(x))])\n",
    "    return sigmoid(z)\n",
    "neuron([3,2],-2,[1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ff8f4-da7a-42e4-afda-add8eff56094",
   "metadata": {},
   "source": [
    "Um zu beurteilen, wie nah/ähnlich zwei Vektoren einander sind, wird der quadrierte euklidische Abstand benötigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f50a7a-9c03-4ef3-94bc-1ef9f624dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x,y): # Quadrat des Abstands zwischen zwei Vektoren\n",
    "    return sum([(x[i]-y[i])**2 for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e6489",
   "metadata": {},
   "source": [
    "Als Nächstes soll ein kleines neuronales Netz programmiert werden. Das folgende definiert zwei Gewichtsmatrizen und zwei Vektoren. All diese Parameter des Netzes werden im Lernprozess später bestimmt. Außerdem werden Funktion definiert, mit denen man solche Matrizen in einen einzigen großen Vektor umwandelt und umgekehrt. Das ist nötig, weil die verwendete Optimierungsroutine nur einen Vektor als Eingabe erwartet.\n",
    "Alle Vektoren und Matrizen werden nicht als Listen behandelt, sondern als Objekte vom Datentyp np.array. Das hat den Vorteil, dass man den Operator @ für die Multiplikation einer Matrix mit einem Vektor verwenden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd0f121-580d-41c9-9f9a-039e575f33d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True]]),\n",
       " array([[ True,  True,  True],\n",
       "        [ True,  True,  True]]),\n",
       " array([ True,  True,  True]),\n",
       " array([ True,  True])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1=np.zeros((3, 4)) # Erzeugung von je zwei Matrizen und Vektoren, zunächst mit Nullen gefüllt\n",
    "W2=np.zeros((2, 3))\n",
    "B1=np.zeros((3))\n",
    "B2=np.zeros((2))\n",
    "def M2V(W1,W2,B1,B2): # verwandelt die Vektoren und Matrizen in einen einzigen großen Vektor\n",
    "    return np.hstack((W1.flatten(), W2.flatten(), B1.flatten(), B2.flatten()))\n",
    "def V2M(x): # Umkehroperation zu M2V\n",
    "    lenW1=np.prod(np.shape(W1))\n",
    "    lenW2=np.prod(np.shape(W2))\n",
    "    lenB1=np.prod(np.shape(B1))\n",
    "    lenB2=np.prod(np.shape(B2))\n",
    "    w1 = x[:lenW1].reshape(np.shape(W1))\n",
    "    w2 = x[lenW1:lenW1+lenW2].reshape(np.shape(W2))\n",
    "    b1 = x[lenW1+lenW2:lenW1+lenW2+lenB1].reshape(np.shape(B1))\n",
    "    b2 = x[lenW1+lenW2+lenB1:].reshape(np.shape(B2))\n",
    "    return [w1,w2,b1,b2]\n",
    "x0 = M2V(W1, W2, B1, B2) # Die Matrizen als ein großer Vektor\n",
    "[V2M(x0)[0]==W1, V2M(x0)[1]==W2, V2M(x0)[2]==B1, V2M(x0)[3]==B2] # Rückkonvertierung liefert wieder die Matrizen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f451e59",
   "metadata": {},
   "source": [
    "Das kleine Beispiel-Netz betseht aus zwei Lagen von Neuronen, die nacheinader angewendet werden. Das Netz ist eine Funktion R^4 -> R^2, die Parameter werden als optionale Variablen angegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcb1581-cd54-4223-b46b-cc9da8cb9d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def net(X,w1=W1,w2=W2,b1=B1,b2=B2): return sigmoidVect(w2@sigmoidVect(w1@X+b1)+b2)\n",
    "net(np.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49006fd1",
   "metadata": {},
   "source": [
    "Die Eingaben des Netzes sind Vektoren aus dem R^4, die die vier Pixel eines 2x2-Bildes darstellen sollen. Die Ausgabeneuronen sollen hohe Werte bei vertikalen beziehungsweise horizontalen Strukturen annehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247c73fc-dff7-4f5c-8545-c8944af41226",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata= [\n",
    "    [[1,0,1,0],[1,0]], [[0,1,0,1],[1,0]], \n",
    "    [[1,1,0,0],[0,1]], [[0,0,1,1],[0,1]], \n",
    "    [[1,1,1,1],[0.5,0.5]],[[0,0,0,0],[0.5,0.5]], \n",
    "    [[0,1,0,0],[0.5,0.5]], [[1,0,0,0],[0.5,0.5]],  \n",
    "    [[0.9,0.1,1,0],[0.9,0.1]], [[0.1,1,0,0.9],[0.9,0.1]],  \n",
    "    [[1,0,1,1],[0.5,0.5]], [[0,1,1,1],[0.5,0.5]],  \n",
    "    [[1,1,0,1],[0.5,0.5]], [[1,1,1,0],[0.5,0.5]]  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd71103-f11f-4d75-b8cb-66b8c7ede42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Folgende ist die zu minimierende Zielfunktion des Lernens: \n",
    "def F(x):\n",
    "    [w1,w2,b1,b2]=V2M(x)\n",
    "    return sum([distance(d[1],net(d[0],w1,w2,b1,b2)) for d in trainingdata])\n",
    "opt=minimize(F,M2V(W1,W2,B1,B2),method='BFGS')\n",
    "[W1opt,W2opt,B1opt,B2opt]=V2M(opt.x)\n",
    "# das Folgende ist das trainierte Netz\n",
    "def netopt(X): return net(X,W1opt,W2opt,B1opt,B2opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c850c6-e97c-4bfc-bc90-3cede8623150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29004597e-174, 1.00000000e+000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netopt(np.array([1,1,0.1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398e0559-247f-4d78-ae6c-9b63296512a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63049359, 0.37050827])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netopt(np.array([1,0,0.9,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac56346-382f-4342-9350-d97e5201f8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63049359, 0.37050827])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netopt(np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796fb37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29004597e-174, 1.00000000e+000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netopt(np.array([1,1,0.01,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdbb4e-c8d1-4cfb-8e77-242b930f76fd",
   "metadata": {},
   "source": [
    "Arbeitsaufträge:\n",
    "1) Verändern Sie die Trainingsdaten so, dass das Netz lernt, diagonale Linien zu erkennen.\n",
    "2) Verändern Sie die Netzstruktur, so dass es vier Ausgabe-Neuronen gibt, je eine soll signalisieren, dass die Struktur überwiegend horizontal, vertikal, diagonal fallend oder diagonal steigend ist. Erhöhen Sie dazu auch die Zahl der Neuronen in der mittleren Schicht auf 5. Stellen Sie passende Trainingsdaten dafür zusammen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdeb63-eab4-411c-aac7-4a9fcd8236f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
