{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dffd6f3-a919-4586-a814-793306f9d9c2",
   "metadata": {},
   "source": [
    "# Backup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92042e9b-5ef9-4006-92e5-33d26236ee14",
   "metadata": {},
   "source": [
    "Suche nach dem Minimum einer Funktion in einer Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87990c0c-12f2-44bc-a3fa-1c6595c2e125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Min des cos, Startwert 0.1', 3.141601562500001]\n",
      "['Min des cos, Startwert -0.1', -3.141601562500001]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def min1(f,x0):\n",
    "    delta=0.1 # anfängliche Schrittweite\n",
    "    while delta>0.0001:\n",
    "        while f(x0)>f(x0+delta) or f(x0)>f(x0-delta): # Solange Verbesserung möglich\n",
    "            if f(x0)>f(x0+delta): x0=x0+delta # gehe nach rechts\n",
    "            else: x0=x0-delta # oder links\n",
    "        delta=delta/2\n",
    "    return x0\n",
    "        \n",
    "print(['Min des cos, Startwert 0.1',min1(math.cos,0.1)])        \n",
    "print(['Min des cos, Startwert -0.1',min1(math.cos,-0.1)])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1264de6-2f36-49b6-a5bd-446c69cea5e0",
   "metadata": {},
   "source": [
    "Minimierung einer reellen Funktion auf R^n: Die Stelle ist also ein Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09dac21e-2ea1-4653-9a4d-7dab12b3f1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Min in R^2', [2.0000000000000018, 3.0000000000000027]]\n"
     ]
    }
   ],
   "source": [
    "def minN(f,x0):\n",
    "    i=0\n",
    "    def fi(x): # Funktion R->R, bei der nur die i-te Komponente variabel\n",
    "        return f(x0[:i]+[x]+x0[i+1:])\n",
    "    for runde in range(100): # Anzahl der Durchgänge\n",
    "        for i in range(len(x0)): # Minimiere nacheinader bzgl der i-ten Variable\n",
    "            x0[i]=min1(fi,x0[i])\n",
    "    return x0\n",
    "\n",
    "def g(x): return (x[0]-2)**2+(x[1]-3)**2\n",
    "print(['Min in R^2',minN(g,[5,5])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f66727-f45d-433f-84f1-65746358438d",
   "metadata": {},
   "source": [
    "Der Programmcode oben zeigt, dass die Suche nach einem Minimum einer Funktion R^n->R algorithmisch durchgeführt werden kann. Allerdings gibt es viel schnellere Implementationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed8497d-c555-40e3-ab9d-0673c27f90ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99999986, 3.00000019])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "x0 = np.array([5,5])\n",
    "res = minimize(g, x0)\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabba1b1-0db6-4748-a711-369d9a2be03d",
   "metadata": {},
   "source": [
    "Lineare Regression ist die Minimierung der Summe der quadratischen Abweichungen zwischen Daten und einem von einem Modell-Term vorhergesagten Wert. Die Parameter m,b der linearen Funktion y=m*x+b werden in einem Vektor x0=[m,b] gespeichert  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4756a620-9541-44ab-9152-811ce369c55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59999997, 1.50000007])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[[1,3],[2,5],[3,6],[4,8]]\n",
    "def FehlerQuadrat(x0):\n",
    "    m=x0[0]; b=x0[1] # Parameter der Ausgleichsgerade\n",
    "    return sum([(d[1]-(m*d[0]+b))**2 for d in data]) # Summe der Abweichungsquadrate\n",
    "opt=minimize(FehlerQuadrat, np.array([0,0]))\n",
    "opt.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40e350-9087-4437-990c-a818590febf4",
   "metadata": {},
   "source": [
    "## Simples Neuron (Code von Sarah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1c55ac-98e9-43e8-9f96-2b7a05d1e00f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20586e5d-beec-465f-a239-851b81975bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trainingsdaten (einfache lineare Trennung)\n",
    "X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\n",
    "y_train = np.array([1, 1.1, 1, 1])\n",
    "\n",
    "# Testdaten (ähnlich zu den Trainingsdaten)\n",
    "X_test = np.array([[1, 1.2], [1.2, 1.2], [2.1, 1.1], [2, 1.8]])\n",
    "y_test = np.array([1.1, 1.2, 0.9, 1.03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1d32fe-1082-41b0-a50a-acc1fc99b736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimale Gewichte: [2.70182265 2.30182265 1.29432963]\n",
      "Fehler auf Trainingsdaten: 3.3734273439031776e-06\n",
      "Fehler auf Testdaten: 0.06139036056182702\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid Aktivierungsfunktion\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Neuron-Funktion\n",
    "def neuron(w, x):\n",
    "    w1, w2, b = w\n",
    "    z = w1 * x[0] + w2 * x[1] + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "# Zielfunktion für die Minimierung\n",
    "def loss_function(w, X, y):\n",
    "    predictions = np.array([neuron(w, x) for x in X])\n",
    "    sum_of_squared_errors = np.sum( (predictions - y) ** 2)\n",
    "    return sum_of_squared_errors\n",
    "\n",
    "# Trainingsdaten (einfache lineare Trennung)\n",
    "X_train = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\n",
    "y_train = np.array([1, 1, 1, 1])\n",
    "\n",
    "# Testdaten (ähnlich zu den Trainingsdaten)\n",
    "X_test = np.array([[1, 1.2], [1.2, 1.2], [2.1, 1.1], [2, 1.8]])\n",
    "y_test = np.array([1.1, 1.2, 0.9, 1.03])\n",
    "\n",
    "# Initialwerte für w1, w2 und b\n",
    "initial_weights = np.array([1.5, 1.1, 0.1])\n",
    "\n",
    "# Minimiere die Zielfunktion, um optimale Gewichte zu finden\n",
    "result = minimize(loss_function, initial_weights, args=(X_train, y_train))\n",
    "optimal_weights = result.x\n",
    "\n",
    "print(\"Optimale Gewichte:\", optimal_weights)\n",
    "\n",
    "# Berechne den Fehler auf den Trainings- und Testdaten\n",
    "train_error = loss_function(optimal_weights, X_train, y_train)\n",
    "test_error = loss_function(optimal_weights, X_test, y_test)\n",
    "\n",
    "print(\"Fehler auf Trainingsdaten:\", train_error)\n",
    "print(\"Fehler auf Testdaten:\", test_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
