{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aff9eed-4097-4058-93bd-2be91cc193d9",
   "metadata": {},
   "source": [
    "# Embedding-Vektoren in Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8c802-28f6-455d-9613-96b565a8f6dd",
   "metadata": {},
   "source": [
    "Das Folgende zeigt, wie man die Embedding-Vektoren erhalten und mit ihnen rechnen kann. Um die nötigen Komponenten zu installieren, empfiehlt es sich, die Anaconda-Python-Distribution zu benutzen. Dann kann man auf der Konsole des Betriebssystems die folgenden Befehle geben:\n",
    "\n",
    "conda create -n lmm-demo python=3.8\n",
    "\n",
    "conda activate lmm-demo\n",
    "\n",
    "conda install -c conda-forge transformers\n",
    "\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d64aa-0085-468f-942b-f49706e11dfa",
   "metadata": {},
   "source": [
    "Das folgende zeigt, wie man die Vektoren bekommt und mit ihnen rechnet. Die Ähnlichkeiten sind bei Googles Bert generell recht hoch, aber die Unterschiede sind schon so, wie man es erwartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fa1ea2-7113-4f6b-ba0a-0b1893e656c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infos zum Embedding von 'queen': Dimension 768, Länge des Vektors 14.485814105400754\n",
      "Skalarprodukt von 'man' und 'woman' : 205.74431258703873\n",
      "Skalarprodukt von 'man' und 'queen' : 202.07533714101365\n",
      "Skalarprodukt von 'man' und '7' : 195.95884762206447\n",
      "Cosinus-Ähnlichkeit von 'man' und 'woman' : 0.9754535546998419\n",
      "Cosinus-Ähnlichkeit von 'man' und 'queen' : 0.9619835011071921\n",
      "Cosinus-Ähnlichkeit von 'man' und '7' : 0.9384714423875936\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import math\n",
    "\n",
    "# Laden des M odells - hier Bert (beim erstn mal dauert das lange) \n",
    "model_name = \"bert-base-uncased\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    # Erzeugen der Token\n",
    "    inputs = tokenizer(word, return_tensors='pt')    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extraktion der mbeddings\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    if len(embeddings)>1: print(f\"Es gab {len(embeddings)} Tokens. Nur das erste wird genutzt.\")\n",
    "    e=embeddings[0][0]  # Embedding des ersten Tokens\n",
    "    return e.tolist() # Rückgabe als Python-Liste\n",
    "\n",
    "embedMan = get_word_embedding(\"man\")\n",
    "embedWoman = get_word_embedding(\"woman\")\n",
    "embedKing = get_word_embedding(\"king\")\n",
    "embedQueen = get_word_embedding(\"queen\")\n",
    "embed7 = get_word_embedding(\"seven\")\n",
    "\n",
    "# Vektoroperationen mit Listen als Vektoren\n",
    "def vadd(a,b): return([a[i]+b[i] for i in range(min(len(a),len(b)))])\n",
    "def vsub(a,b): return([a[i]-b[i] for i in range(min(len(a),len(b)))])\n",
    "def vsmul(s,a): return([s*a[i] for i in range(len(a))])\n",
    "def skalarProdukt(a,b): return(sum([a[i]*b[i] for i in range(min(len(a),len(b)))]))\n",
    "def vnorm(a): return(math.sqrt(skalarProdukt(a,a)))   \n",
    "def vnormed(a): return(vsmul(1.0/vnorm(a),a))    \n",
    "def cosineSim(a,b): return(skalarProdukt(vnormed(a),vnormed(b)))\n",
    "    \n",
    "print(f\"Infos zum Embedding von 'queen': Dimension {len(embedQueen)}, Länge des Vektors {vnorm(embedQueen)}\")\n",
    "\n",
    "# Scalar product (dot product)\n",
    "print(f\"Skalarprodukt von 'man' und 'woman' : {skalarProdukt(embedMan,embedWoman)}\")\n",
    "print(f\"Skalarprodukt von 'man' und 'queen' : {skalarProdukt(embedMan,embedQueen)}\")\n",
    "print(f\"Skalarprodukt von 'man' und '7' : {skalarProdukt(embedMan,embed7)}\")\n",
    "print(f\"Cosinus-Ähnlichkeit von 'man' und 'woman' : {cosineSim(embedMan,embedWoman)}\")\n",
    "print(f\"Cosinus-Ähnlichkeit von 'man' und 'queen' : {cosineSim(embedMan,embedQueen)}\")\n",
    "print(f\"Cosinus-Ähnlichkeit von 'man' und '7' : {cosineSim(embedMan,embed7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0e5bd-61b3-4cf6-95a5-188d5f03e39b",
   "metadata": {},
   "source": [
    "Mit den Vektoren kann man rechnen: König-Mann+Frau sollte in der Nähe von Königin liegen. Die Berechnung ist etwas geringer als erwartet, aber immerhin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f768682-b222-4807-ba86-6e3f4ed23612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus-Ähnlichkeit von 'queen' und der berechneten Königin : 0.9572869600125741\n"
     ]
    }
   ],
   "source": [
    "queenBerechnet=vadd(vsub(embedKing,embedMan),embedWoman)\n",
    "print(f\"Cosinus-Ähnlichkeit von 'queen' und der berechneten Königin : {cosineSim(embedQueen,queenBerechnet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb2c56-19a4-4457-8b92-bd53488b168b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
